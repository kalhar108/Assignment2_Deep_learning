# CMPE-258 Assignment 1 - Deep Learning (Spring 2026, Sec 49)

## ğŸ“‹ Overview

This repository contains all four parts of Assignment 1 for CMPE-258 Deep Learning. Each part demonstrates different aspects of modern AI/ML development including multimodal AI, full-stack web development with AI, cross-platform mobile development, and neural network implementation.

---

## ğŸ“ Repository Structure

```
assignment1/
â”œâ”€â”€ README.md
â”œâ”€â”€ partA/
â”‚   â””â”€â”€ CMPE258_Assignment1_PartA_Multimodal_AI.ipynb
â”œâ”€â”€ partB/
â”‚   â”œâ”€â”€ spendwise-web-app.html
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ partC/
â”‚   â”œâ”€â”€ mindflow-mobile-app.html    (Interactive prototype)
â”‚   â”œâ”€â”€ main.dart                    (Flutter source)
â”‚   â””â”€â”€ README.md
â””â”€â”€ partD/
    â””â”€â”€ CMPE258_Assignment1_PartD_MNIST.ipynb
```

---

## Part A: Multimodal AI with Google Gemini ğŸ¨

### Description
A comprehensive Google Colab notebook demonstrating the latest multimodal AI capabilities using Google's Gemini models.

### Features Demonstrated (All Free â€” No API Keys!)
| Feature | Model | Description |
|---------|-------|-------------|
| Image Generation | Stable Diffusion 2.1 | 4 creative images from text (cyberpunk, abstract, nature-tech, miniature) |
| Image Captioning | BLIP-Large | Automatic descriptions of photos, art, and AI images |
| Visual QA | BLIP-VQA-Large | Question answering about image content |
| Zero-Shot Classification | CLIP | Classify images into any custom categories |
| Text Conversations | Google Gemma 2B | Creative stories, technical explanations, code gen, debates |
| Image Classification | ViT | Top-5 ImageNet predictions |
| Attention Visualization | ViT | Where the model focuses (heatmaps) |

### How to Run
1. Open the notebook in [Google Colab](https://colab.google/notebooks/)
2. Select **GPU runtime** (Runtime â†’ Change runtime type â†’ T4 GPU)
3. Run all cells sequentially â€” **no API key needed!**

### Video Walkthrough
ğŸ“¹ [Link to YouTube walkthrough]

---

## Part B: SpendWise AI - Smart Expense Tracker (Web App) ğŸ’°

### Description
A full-stack web application built as an AI-powered expense tracker with smart insights, interactive dashboard, and an AI chat assistant.

### UI/UX Design: Dark Cyberpunk Financial Dashboard
- **Theme:** Dark mode with neon accents (purple/teal)
- **Font:** DM Sans + Instrument Serif
- **Layout:** Grid-based dashboard with cards
- **Key Differentiator:** Professional financial dashboard feel with glowing elements

### Features
- âœ… Interactive expense/income tracking
- âœ… Real-time donut chart for category breakdown
- âœ… AI-powered smart insights (spending patterns, savings tips)
- âœ… AI Chat assistant for financial queries
- âœ… Add/manage transactions with modal
- âœ… CSV export functionality
- âœ… Responsive design (mobile + desktop)

### Tech Stack
- HTML5, CSS3 (Custom Properties, Grid, Flexbox)
- Vanilla JavaScript (no frameworks)
- AI Chat simulation (can be connected to Gemini API)

### Screenshots
*Dark dashboard with expense tracking, donut chart, and AI insights*

### How to Run
Open `spendwise-web-app.html` in any modern browser.

---

## Part C: MindFlow - AI Mood & Wellness Journal (Mobile App) ğŸ§˜

### Description
A cross-platform mobile application built with Flutter, featuring mood tracking, wellness journaling, and AI-powered insights using Google Gemini.

### UI/UX Design: Warm Organic Wellness Theme
- **Theme:** Light warm background (#FBF8F3) with colorful accents
- **Font:** Nunito + Playfair Display
- **Layout:** Card-based mobile-first with bottom navigation
- **Key Differentiator:** Soft, inviting wellness app feel (vs Part B's sharp financial dashboard)

### Design Differences from Part B (Web App)
| Aspect | Part B (SpendWise) | Part C (MindFlow) |
|--------|-------------------|-------------------|
| Theme | Dark cyberpunk | Light warm organic |
| Colors | Purple/Teal neon | Pastel/Soft gradients |
| Typography | DM Sans (modern) | Nunito (friendly rounded) |
| Layout | Grid dashboard | Card-based vertical scroll |
| Mood | Professional/corporate | Personal/wellness |
| Navigation | Top header + sidebar chat | Bottom tab bar + FAB |

### Features
- âœ… Daily mood check-in (5-point emoji scale)
- âœ… Journal entries with tags
- âœ… Wellness tracking (sleep hours, water intake, exercise)
- âœ… Weekly mood chart visualization
- âœ… AI-powered weekly summaries and insights
- âœ… Mood streak tracking
- âœ… Per-class mood analytics
- âœ… 4 pages: Home, Journal, Insights, Profile

### Tech Stack
- **Framework:** Flutter (Dart)
- **AI:** Google Gemini 2.0 Flash API
- **Charts:** fl_chart
- **Storage:** shared_preferences
- **Prototype:** HTML/CSS/JS (pixel-perfect Flutter-like design)

### How to Run
**Interactive Prototype:** Open `mindflow-mobile-app.html` in a mobile browser or use Chrome DevTools mobile view (430px width).

**Flutter App:**
```bash
cd partC/flutter_app
flutter pub get
flutter run
```

---

## Part D: MNIST Neural Network Classifier ğŸ§ 

### Description
A comprehensive Keras implementation of MNIST digit classification with three model architectures and extensive evaluation metrics, as demonstrated in class.

### Models
| Model | Architecture | Key Features |
|-------|-------------|-------------|
| Dense Network | 784â†’256â†’128â†’10 | Baseline, dropout |
| Standard CNN | 2Ã—Conv blocks + Dense | BatchNorm, MaxPool, Dropout |
| Advanced CNN | 3Ã—Conv blocks + GAP | Data augmentation, L2 regularization, GlobalAveragePooling |

### Metrics & Visualizations
- âœ… Training/Validation accuracy & loss curves
- âœ… Confusion matrix (raw + normalized)
- âœ… Per-class precision, recall, F1-score
- âœ… Classification report
- âœ… ROC curves with AUC (per class)
- âœ… Precision-Recall curves with AP
- âœ… Model comparison table
- âœ… Misclassified samples analysis
- âœ… Prediction confidence distribution
- âœ… Grad-CAM visualization (what the CNN sees)
- âœ… Data augmentation examples

### Expected Results
| Model | Accuracy | Parameters |
|-------|----------|-----------|
| Dense Network | ~97-98% | ~235K |
| Standard CNN | ~99.2%+ | ~400K+ |
| Advanced CNN | ~99.4%+ | ~200K+ |

### How to Run
1. Open `CMPE258_Assignment1_PartD_MNIST.ipynb` in Google Colab
2. Select GPU runtime (Runtime â†’ Change runtime type â†’ GPU)
3. Run all cells

### Video Walkthrough
ğŸ“¹ [Link to YouTube walkthrough]

---

## ğŸ¥ Video Walkthroughs

| Part | Description | Link |
|------|-------------|------|
| A | Multimodal AI Colab Demo | [YouTube](#) |
| B | SpendWise Web App Demo | [YouTube](#) |
| C | MindFlow Mobile App Demo | [YouTube](#) |
| D | MNIST Classifier Demo | [YouTube](#) |

---

## ğŸ› ï¸ Technologies Used

- **AI/ML:** Stable Diffusion, BLIP, CLIP, Gemma 2B, ViT, TensorFlow/Keras
- **Web:** HTML5, CSS3, JavaScript
- **Mobile:** Flutter/Dart
- **Data Science:** NumPy, Matplotlib, Seaborn, Scikit-learn, HuggingFace Transformers
- **Tools:** Google Colab (free GPU), Git/GitHub

---

## ğŸ“ Notes

- All artifacts are checked into this GitHub repository
- Each part has a video walkthrough demonstrating the functionality
- Part B (Web) and Part C (Mobile) intentionally have **different UI/UX designs** to showcase variety
- **No API keys required** â€” all AI models are free and open-source (HuggingFace)
- Part A runs on Colab's free T4 GPU

---

## ğŸ‘¤ Author

CMPE-258 Deep Learning - Spring 2026, Section 49
